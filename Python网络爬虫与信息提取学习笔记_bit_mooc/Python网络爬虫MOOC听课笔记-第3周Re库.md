# Python网络爬虫MOOC听课笔记-第3周

## 正则表达式介绍

requests

BeautifulSoup

re

正则表达式：用来**简洁**表达一组字符串的表达式。

## 正则表达式的语法

语法由字符和操作符组成。

### 常用操作符

```
.
[]
[^]
*
+
?
|
{m}
{m,n}
^
$
()
\d
\w

```

### 经典正则表达式实例

^[A-Za-z]+$	由26个字母组成的字符串

^[A-Za-z0-9]+$	由26个字母和数字组成的字符串

## Re库的使用

是python 的标准库，不需要额外安装。

import re

re库使用raw string类型表示正则表达式，表示为r'text'

raw string类型是不包含转移符号的字符串。

re库也可以使用string类型，但是更繁琐，因为string中的反斜线会混淆正则表达式的反斜线。

### 主要功能函数6个

| 函数          | 说明                                                         |
| ------------- | ------------------------------------------------------------ |
| re.search()   | 在一个字符串中搜索匹配正则表达式的第一个位置，返回match对象  |
| re.match()    | 从一个字符串的开始位置起匹配正则表达式，返回match对象        |
| re.findall()  | 搜索字符串，以列表类型返回全部能匹配的子串                   |
| re.split()    | 将一个字符串按照正则表达式匹配结果进行分割，返回子串的 列表类型 |
| re.finditer() | 搜索字符串，返回一个匹配结果的迭代类型，每个迭代元素是match对象 |
| re.sub()      | 在一个字符串中替换所有正则表达式的子串，返回替换后的字符串   |

Re库的另一种等价用法

上述是函数式用法。

面向对象用法：编译后的多次操作，regex = re.compile()

| 函数             | 用法                                                         |
| ---------------- | ------------------------------------------------------------ |
| regex.search()   | 在一个字符串中搜索匹配正则表达式的第一个位置，返回match对象  |
| regex.match()    | 从一个字符串的开始位置起汽配正则表达式，返回match对象        |
| regex.findall()  | 搜索字符串，以列表类型返回全部能匹配的子串                   |
| regex.split()    | 将一个字符串按照正则表达式匹配结果进行分割，返回列表类型     |
| regex.finditer() | 搜索字符串，返回一个匹配结果的迭代类型，每个迭代元素是match对象 |
| regex.sub()      | 在一个字符串中替换所有匹配正则表达式的子串，返回替换后的字符串 |

在上面这6个函数使用的时候，注意需要将函数参数中正则表达式的参数部分去掉，因为re.compile()已经给出了。

## Re库的match对象

match对象主要有四个属性

* .string

* .re

* .pos

* .endpos

match对象的方法

* .group(0)	获得匹配的字符串

* .start()	匹配字符串在原始字符串的开始位置

* .end()

* .span()

## Re库的贪婪匹配和最小匹配

Re库默认采用贪婪匹配，即输出匹配最长的子串。

最小匹配在贪婪匹配上进行扩展，最小匹配操作符

就是在操作符后加一个问号，来获得最小匹配的结果。

| 操作符 | 说明                                  |
| ------ | ------------------------------------- |
| *?     | 前一个字符0次或无限次扩展，最小匹配   |
| +?     | 前一个字符1次或无限次扩展，最小匹配   |
| ??     | 前一个字符0次或1次扩展，最小匹配      |
| {m,n}? | 扩展前一个字符m至n次（含n），最小匹配 |

## 实例 淘宝商品信息定向爬虫

功能描述

* 目标 获取淘宝搜索页面的信息，提取其中的商品名称和价格
* 理解 淘宝的搜索接口；翻页的处理
* 技术路线 reqeusts re

淘宝搜索"书包"

程序的结构设计

步骤1 提交商品搜索请求，循环获取页面

步骤2 对于每个页面，提取商品名称和价格信息

步骤3 将信息输出到屏幕上。

## 实例 股票数据定向爬虫

 目的 获取上交所和深交所的股票名称和价格

输出 保存到文件中

技术路线 requests-re-BeautifulSoup

候选网站 新浪股票和百度股票

选取网页原则： 股票信息是静态存放在html中，非js代码生成，没有robotx协议限制

选取方法 查看网页源代码

选取心态 不要纠结于某一个网站，多找信息源尝试

打开网页发现，新浪股票中某一个股票的价格在源代码中找不到，说明可能是js生成的。而百度股票可以。

程序的结构设计

1 从东方财富网获取股票列表

2 根据股票列表逐个到百度股票获取个股信息

3 将结果存储到文件